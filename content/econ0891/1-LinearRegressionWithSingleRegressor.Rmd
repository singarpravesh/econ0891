--- 
title: "1: Linear Regression with Single Regressor"
author: "pravesh"
date: "2021-03-31"
output: html_document
---

## Introduction
- Reference book (Theory): **Introduction to Econometrics** by *Stock and Watson*, 3e.
- The data are taken from the [Companion Website](http://wps.pearsoned.co.uk/ema_ge_stock_ieupdate_3/251/64413/16489872.cw/index.html){target="_blank"} for Introduction to Econometrics book.


# Linear Regression


**Objective : Generate Figure 4.2**
```{r, warning=FALSE, echo = FALSE, fig.cap="Scatterplot of TestScore vs Student-Teacher ratio (California School District Data"}
caschool <- readxl::read_xlsx('~/blogdown/econ0891/content/econ0891/1-LinearRegressionWithSingleRegressor/caschool.xlsx')
plot(caschool$testscr ~ caschool$str,
     xlab = "Student-teacher ratio",
     ylab = "Test score", pch = 20, xlim = c(10,30),
     ylim = c(600, 720), las = 1)
```

**Objective : Generate Figure 4.2**
```{r, eval=FALSE}
# read the data
caschool <- readxl::read_xlsx("~/blogdown/econ0891/content/econ0891/1-LinearRegressionWithSingleRegressor/caschool.xlsx")

# check the structure of the loaded dataset
str(caschool)
```

Check the description of the dataset caschool.xlsx [here](californiatestscores.docx){target="_blank"}

```{r}
names(caschool)
```

## {.smaller .vcenter}

```{r, fig.cap="Scatterplot of TestScore vs Student-Teacher ratio (California School District Data)"}
plot(caschool$testscr ~ caschool$str,
     xlab = "Student-teacher ratio",
     ylab = "Test score", pch = 20, xlim = c(10,30),
     ylim = c(600, 720), las = 1)
```

 

# The OLS estimator


Consider **Table 4.1** in the textbook which gives the summary of the distribution of student-teacher ratio and test scores.
```{r, echo=FALSE}
# compute sample averages of STR and score
avg_str <- mean(caschool$str) 
avg_score <- mean(caschool$testscr)

# compute sample standard deviations of STR and score
sd_str <- sd(caschool$str) 
sd_score <- sd(caschool$testscr)

# set up a vector of percentiles and compute the quantiles 
quantiles <- c(0.10, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9)
quant_str <- quantile(caschool$str, quantiles)
quant_score <- quantile(caschool$testscr, quantiles)

# gather everything in a data.frame 
(DistributionSummary <- data.frame(Average = c(avg_str, avg_score), 
                                  StandardDeviation = c(sd_str, sd_score), 
                                  quantile = rbind(quant_str, quant_score)))
```

 

**Table 4.1**
```{r, eval=FALSE}
# compute sample averages of STR and score
avg_str <- mean(caschool$str) 
avg_score <- mean(caschool$testscr)

# compute sample standard deviations of STR and score
sd_str <- sd(caschool$str) 
sd_score <- sd(caschool$testscr)

# set up a vector of percentiles and compute the quantiles 
quantiles <- c(0.10, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9)
quant_str <- quantile(caschool$str, quantiles)
quant_score <- quantile(caschool$testscr, quantiles)

# gather everything in a data.frame 
(DistributionSummary <- data.frame(Average = c(avg_str, avg_score), 
                        StandardDeviation = c(sd_str, sd_score), 
                        quantile = rbind(quant_str, quant_score)))
```


 

Estimate the regression coefficents in
$$
\hat{TestScore} = \hat{\beta_0} + \hat{\beta_1}STR
$$
Where, $TestScore$ is the average test score in the district, and $STR$ is the student-teacher ratio.
$$
\hat{\beta_1} = \frac{\sum{(X_i -\bar{X})(Y_i - \bar{Y})}}{\sum{(X_i - \bar{X})^2}}\\
\hat{\beta_o} =  \bar{Y} - \hat{\beta_1}\bar{X}
$$

 

- The `lm()` function is used to fit a <u>**L**</u>inear <u>**M**</u>odel.
- Usage
```{r, eval = FALSE}
lm(formula, data, subset)
```
- The California Schools model
```{r}
# fit a linear model and save it to an `lm` object
lm_model1 <- lm(formula = testscr ~ str, data = caschool)
class(lm_model1)
```

 

You can directly print the `lm_model1` output
```{r}
lm_model1
```


## {.smaller}
Or, you can also print the `summary()`.
```{r}
summary(lm_model1)
```

 

- Now, let's plot Fig 4.3
- First, we shall extract the coefficients from `lm_model1`
```{r}
b1 <- coef(lm_model1)[[1]]
b2 <- abs(coef(lm_model1)[[2]])

```

- We shall also need `expr()` from `rlang` package to add Mathematical Annotation in R.

```{r}
library(rlang) 
```
- Use `?plotmath()` and `demo(plotmath)` for usage.


## {.smaller .vcenter}

```{r}
plot(caschool$testscr ~ caschool$str,
     xlab = "Student-teacher ratio",
     ylab = "Test score", pch = 20, xlim = c(10,30),
     ylim = c(600, 720), las = 1)

# add the model fit
abline(lm_model1, col = "blue", lwd = 2)
text(25, 710, expr(paste(hat(TestScore)~"="~ !!b1~"-"~ !!b2~x~STR)), cex = 0.8)
arrows(25,702, 28,640, length = 0)
```

## Prediction
```{r}
# make a vector of new values for `str`.
new_str <- data.frame(str = c(29.36, 31.54, 35.22))

# predict
yhat <- predict(lm_model1, new_str)
names(yhat) <- paste("str=", c(29.36, 31.54, 35.22))
yhat
```


# Measures of fit

## The $R^2$ {.build}
- Assign the summary of the `lm_model1` in `summary.lm` object.
```{r}
s <- summary(lm_model1)
class(s)
```

## The $R^2$ {.build}

```{r}
names(s)

# extract and print Rsquared value
(r2 <- s$r.squared)
```

## Standard error of the regression (SER)
$$
SER = \sqrt\frac{SSR}{n-2}
$$


```{r}
# Compute SSR (Residual sum of squares)
ssr <- sum(s$residuals^2)

# compute SER
n <- nrow(caschool)
(ser <- sqrt(ssr/(n-2)))
```


# The sensitivity of OLS to large outliers.

 

**Fig 4.5**
```{r, echo=FALSE}
# set seed
set.seed(123)

# generate the data
X <- sort(runif(10, min = 30, max = 70))
Y <- rnorm(10 , mean = 200, sd = 50)
Y[9] <- 2000

# fit model with outlier
fit <- lm(Y ~ X)

# fit model without outlier
fitWithoutOutlier <- lm(Y[-9] ~ X[-9])

# plot the results
plot(Y ~ X)
abline(fit)
abline(fitWithoutOutlier, col = "red")

legend("topleft", 
       legend = c("Including outlier",
                  "Excluding outlier"),
       lty = 1, col = c("black", "red"))
```

## {.smaller}

```{r, eval=FALSE}
# set seed
set.seed(123)

# generate the data
X <- sort(runif(10, min = 30, max = 70))
Y <- rnorm(10 , mean = 200, sd = 50)
Y[9] <- 2000

# fit model with outlier
fit <- lm(Y ~ X)

# fit model without outlier
fitWithoutOutlier <- lm(Y[-9] ~ X[-9])

# plot the results
plot(Y ~ X)
abline(fit)
abline(fitWithoutOutlier, col = "red")

legend("topleft", 
       legend = c("Including outlier",
                  "Excluding outlier"),
       lty = 1, col = c("black", "red"))
```


# Exercise

 

1. You will find the data file [Growth.xlsx](Growth.xlsx) and description file [Growth_Description.pdf](Growth_Description.pdf){target="_blank"} for the following questions.

(a). Construct a scatterplot of average annual growth rate *(Growth)* on the average trade share *(TradeShare)*. Does there appear to be a relationship between the variables?

(b). One country, Malta, has a trade share much larger than the other countries. Find Malta on the scatterplot. Does Malta look like an outlier?

(c). Using all observations, run a regression of *Growth* on *TradeShare*.
What is the estimated slope? What is the estimated intercept? Use the regression to predict the growth rate for a country with a trade share of 0.5 and with a trade share equal to 1.0.


 

(d). Estimate the same regression, excluding the data from Malta. Answer the same questions in (c).

(e). Plot the estimated regression functions from (c) and (d). Using the scatterplot in (a), explain why the regression function that includes Malta is steeper than the regression function that excludes Malta.

(f). Where is Malta? Why is the Malta trade share so large? Should Malta be included or excluded from the analysis?

 

2. You will find the data [Earnings_and_Height.xlsx]('Earnings_and_Height.xlsx') and description file [Earnings_and_Height_Description.pdf](Earnings_and_Height_Description.pdf){target="_blank"}

(a). What is the median value of height in the sample?

(b). (i). Estimate average earnings for workers whose height is at most 67 inches.

(ii). Estimate average earnings for workers whose height is greater than 67 inches.

(iii). On average, do taller workers earn more than shorter workers? How much more? What is a 95% confidence interval for the difference in average earnings?

(c). Construct a scatterplot of annual earnings (*Earnings*) on height (*Height*). Notice that the points on the plot fall along horizontal lines. (There are only 23 distinct values of Earnings). Why? (Hint: Carefully read the detailed data description.)

 

(d). Run a regression of Earnings on Height.

(i). What is the estimated slope?
    
(ii). Use the estimated regression to predict earnings for a worker who is 67 inches tall, for a worker who is 70 inches tall, and for a worker who is 65 inches tall.

(e). Suppose height were measured in centimeters instead of inches. Answer the following questions about the Earnings on Height (in cm) regression.

(i). What is the estimated slope of the regression?

(ii). What is the estimated intercept?

(iii). What is the $R^2$?

(iv). What is the standard error of the regression?

 

(f). Run a regression of Earnings on Height, using data for female workers only.

(i). What is the estimated slope?

(ii). A randomly selected woman is 1 inch taller than the average woman in the sample. Would you predict her earnings to be higher or lower than the average earnings for women in the sample? By how much?

(g). Repeat (f) for male workers.

(h). Do you think that height is uncorrelated with other factors that cause earning? That is, do you think that the regression error term, say $u_i$, has a conditional mean of zero, given Height ($X_i$)?